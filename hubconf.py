# -*- coding: utf-8 -*-
"""hubconf

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1k-p4Rn8J8m04aW6BPpfd2MEZd7cs3MXx
"""

import torch
from torch import nn
import torch.nn.functional as F

class cs19b015NN(nn.Module):
    def __init__(cs19b015NN, self, input, output, kernel, strid, pad):

        # Convolution 1
        self.cnn1 = nn.Conv2d(in_channels=self.input, out_channels=self.output, kernel_size=self.kernel, stride=self.strid, padding=self.pad)
        self.relu1 = nn.ReLU()

        # Max pool 1
        self.maxpool1 = nn.MaxPool2d(kernel_size=2)

        # Fully connected 1 (readout)
        self.fc1 = nn.Linear(32 * 7 * 7, 10) 

    def forward(self, x):
        # Convolution 1
        out = self.cnn1(x)
        out = self.relu1(out)

        # Max pool 1
        out = self.maxpool1(out)

        out = out.view(out.size(0), -1)

        # Linear function (readout)
        out = self.fc1(out)

        return out

# sample invocation torch.hub.load(myrepo,'get_model',train_data_loader=train_data_loader,n_epochs=5, force_reload=True)
def get_model(train_data_loader=None, n_epochs=10):
  model = cs19b015NN()  
  
  print ('Returning model... (rollnumber: xx)')
  
  return model

# sample invocation torch.hub.load(myrepo,'get_model_advanced',train_data_loader=train_data_loader,n_epochs=5, force_reload=True)
def get_model_advanced(train_data_loader=None, n_epochs=10,lr=1e-4,config=None):
  
  iter = 0
  

  for epoch in range(n_epochs):

    model = cs19b015NN()
    criterion = nn.CrossEntropyLoss()
    learning_rate = lr
    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)

    for i, (images, labels) in enumerate(train_data_loader):
        # Load images as tensors with gradient accumulation abilities
        images = images.requires_grad_()

        # Clear gradients w.r.t. parameters
        optimizer.zero_grad()

        # Forward pass to get output/logits
        outputs = model(images)

        # Calculate Loss: softmax --> cross entropy loss
        loss = criterion(outputs, labels)

        # Getting gradients w.r.t. parameters
        loss.backward()

        # Updating parameters
        optimizer.step()

  
  iter+=1

  print ('Returning model... (rollnumber: xx)')
  
  return model

def test_model(model1=None, test_data_loader=None):

  model = model1

  accuracy_val, precision_val, recall_val, f1score_val = 0, 0, 0, 0

  for images, labels in test_data_loader:
                # Load images
                images = images.requires_grad_()
                outputs = model(images)

                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)

                # Total correct predictions
                correct += (predicted == labels).sum()

                accuracy_val = 100 * correct / total

  print ('Returning metrics... (rollnumber: xx)')
  
  return accuracy_val, precision_val, recall_val, f1score_val
